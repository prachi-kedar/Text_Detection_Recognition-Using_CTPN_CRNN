{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, imgH, nc, nclass, nh, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        # 1x32x128\n",
    "        self.conv1 = nn.Conv2d(nc, 64, 3, 1, 1)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 64x16x64\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 128x8x32\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3_1 = nn.ReLU(True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
    "        self.relu3_2 = nn.ReLU(True)\n",
    "        self.pool3 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "\n",
    "        # 256x4x16\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.relu4_1 = nn.ReLU(True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.relu4_2 = nn.ReLU(True)\n",
    "        self.pool4 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "\n",
    "        # 512x2x16\n",
    "        self.conv5 = nn.Conv2d(512, 512, 2, 1, 0)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU(True)\n",
    "\n",
    "        # 512x1x16\n",
    "\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        x = self.pool1(self.relu1(self.conv1(input)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3_2(self.conv3_2(self.relu3_1(self.bn3(self.conv3_1(x))))))\n",
    "        x = self.pool4(self.relu4_2(self.conv4_2(self.relu4_1(self.bn4(self.conv4_1(x))))))\n",
    "        conv = self.relu5(self.bn5(self.conv5(x)))\n",
    "        # print(conv.size())\n",
    "\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class CRNN_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, imgH, nc, nclass, nh, leakyRelu=False):\n",
    "        super(CRNN_v2, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        # 1x32x128\n",
    "        self.conv1_1 = nn.Conv2d(nc, 32, 3, 1, 1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(32)\n",
    "        self.relu1_1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv1_2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn1_2 = nn.BatchNorm2d(64)\n",
    "        self.relu1_2 = nn.ReLU(True)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 64x16x64\n",
    "        self.conv2_1 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(64)\n",
    "        self.relu2_1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv2_2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn2_2 = nn.BatchNorm2d(128)\n",
    "        self.relu2_2 = nn.ReLU(True)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 128x8x32\n",
    "        self.conv3_1 = nn.Conv2d(128, 96, 3, 1, 1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(96)\n",
    "        self.relu3_1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3_2 = nn.Conv2d(96, 192, 3, 1, 1)\n",
    "        self.bn3_2 = nn.BatchNorm2d(192)\n",
    "        self.relu3_2 = nn.ReLU(True)\n",
    "        self.pool3 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "\n",
    "        # 192x4x32\n",
    "        self.conv4_1 = nn.Conv2d(192, 128, 3, 1, 1)\n",
    "        self.bn4_1 = nn.BatchNorm2d(128)\n",
    "        self.relu4_1 = nn.ReLU(True)\n",
    "        self.conv4_2 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.bn4_2 = nn.BatchNorm2d(256)\n",
    "        self.relu4_2 = nn.ReLU(True)\n",
    "        self.pool4 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "\n",
    "        # 256x2x32\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "\n",
    "\n",
    "        # 256x2x32\n",
    "\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        x = self.pool1(self.relu1_2(self.bn1_2(self.conv1_2(self.relu1_1(self.bn1_1(self.conv1_1(input)))))))\n",
    "        x = self.pool2(self.relu2_2(self.bn2_2(self.conv2_2(self.relu2_1(self.bn2_1(self.conv2_1(x)))))))\n",
    "        x = self.pool3(self.relu3_2(self.bn3_2(self.conv3_2(self.relu3_1(self.bn3_1(self.conv3_1(x)))))))\n",
    "        x = self.pool4(self.relu4_2(self.bn4_2(self.conv4_2(self.relu4_1(self.bn4_1(self.conv4_1(x)))))))\n",
    "        conv = self.bn5(x)\n",
    "        # print(conv.size())\n",
    "\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 2, \"the height of conv must be 2\"\n",
    "        conv = conv.reshape([b,c*h,w])\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def conv3x3(nIn, nOut, stride=1):\n",
    "    # \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d( nIn, nOut, kernel_size=3, stride=stride, padding=1, bias=False )\n",
    "\n",
    "\n",
    "class basic_res_block(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nOut, stride=1, downsample=None):\n",
    "        super( basic_res_block, self ).__init__()\n",
    "        m = OrderedDict()\n",
    "        m['conv1'] = conv3x3( nIn, nOut, stride )\n",
    "        m['bn1'] = nn.BatchNorm2d( nOut )\n",
    "        m['relu1'] = nn.ReLU( inplace=True )\n",
    "        m['conv2'] = conv3x3( nOut, nOut )\n",
    "        m['bn2'] = nn.BatchNorm2d( nOut )\n",
    "        self.group1 = nn.Sequential( m )\n",
    "\n",
    "        self.relu = nn.Sequential( nn.ReLU( inplace=True ) )\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample( x )\n",
    "        else:\n",
    "            residual = x\n",
    "        out = self.group1( x ) + residual\n",
    "        out = self.relu( out )\n",
    "        return out\n",
    "\n",
    "\n",
    "class CRNN_res(nn.Module):\n",
    "\n",
    "    def __init__(self, imgH, nc, nclass, nh):\n",
    "        super(CRNN_res, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nc, 64, 3, 1, 1)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.res1 = basic_res_block(64, 64)\n",
    "        # 1x32x128\n",
    "\n",
    "        down1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),nn.BatchNorm2d(128))\n",
    "        self.res2_1 = basic_res_block( 64, 128, 2, down1 )\n",
    "        self.res2_2 = basic_res_block(128,128)\n",
    "        # 64x16x64\n",
    "\n",
    "        down2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),nn.BatchNorm2d(256))\n",
    "        self.res3_1 = basic_res_block(128, 256, 2, down2)\n",
    "        self.res3_2 = basic_res_block(256, 256)\n",
    "        self.res3_3 = basic_res_block(256, 256)\n",
    "        # 128x8x32\n",
    "\n",
    "        down3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=(2, 1), bias=False),nn.BatchNorm2d(512))\n",
    "        self.res4_1 = basic_res_block(256, 512, (2, 1), down3)\n",
    "        self.res4_2 = basic_res_block(512, 512)\n",
    "        self.res4_3 = basic_res_block(512, 512)\n",
    "        # 256x4x16\n",
    "\n",
    "        self.pool = nn.AvgPool2d((2, 2), (2, 1), (0, 1))\n",
    "        # 512x2x16\n",
    "\n",
    "        self.conv5 = nn.Conv2d(512, 512, 2, 1, 0)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU(True)\n",
    "        # 512x1x16\n",
    "\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        x = self.res1(self.relu1(self.conv1(input)))\n",
    "        x = self.res2_2(self.res2_1(x))\n",
    "        x = self.res3_3(self.res3_2(self.res3_1(x)))\n",
    "        x = self.res4_3(self.res4_2(self.res4_1(x)))\n",
    "        x = self.pool(x)\n",
    "        conv = self.relu5(self.bn5(self.conv5(x)))\n",
    "        # print(conv.size())\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "        return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
